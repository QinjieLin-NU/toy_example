{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218aca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bundle\n",
    "import time\n",
    "import ray\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae5cd6",
   "metadata": {},
   "source": [
    "## update cluster environments and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a40540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: toy-cluster\n",
      "\n",
      "Setting `max_workers` for node type `head_node` to the global `max_workers` value of 4. To avoid spawning worker nodes of type `head_node`, explicitly set `max_workers: 0` for `head_node`.\n",
      "Note that `max_workers: 0` was the default value prior to Ray 1.3.0. Your current version is Ray 1.6.0.\n",
      "See the docs for more information:\n",
      "https://docs.ray.io/en/master/cluster/config.html#cluster-configuration-node-max-workers\n",
      "https://docs.ray.io/en/master/cluster/config.html#full-configuration\n",
      "Loaded cached provider configuration\n",
      "If you experience issues with the cloud provider, try re-running the command with --no-config-cache.\n",
      "Updating cluster configuration and running full setup.\n",
      "Cluster Ray runtime will be restarted. Confirm [y/N]: y [automatic, due to --yes]\n",
      "\n",
      "<1/1> Setting up head node\n",
      "  Prepared bootstrap config\n",
      "  New status: waiting-for-ssh\n",
      "  [1/7] Waiting for SSH to become available\n",
      "    Running `uptime` as a test.\n",
      "2021-09-02 00:10:35,192\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (uptime)'\n",
      " 17:10:36 up 38 days,  1:26,  0 users,  load average: 1.87, 2.44, 2.47\n",
      "    Success.\n",
      "  Updating cluster configuration. [hash=14c1389d9e44db270d97d721b56b386ac34d503e]\n",
      "  New status: syncing-files\n",
      "  [2/7] Processing file mounts\n",
      "2021-09-02 00:10:36,377\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (mkdir -p /home/ray/dev_ws)'\n",
      "    /home/ray/dev_ws/bundle.py from ./bundle.py\n",
      "2021-09-02 00:10:37,994\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (mkdir -p ~)'\n",
      "  [3/7] No worker file mounts to sync\n",
      "  New status: setting-up\n",
      "  [4/7] No initialization commands to run.\n",
      "  [5/7] Initalizing command runner\n",
      "  [6/7] Running setup commands\n",
      "    (0/4) sudo apt-get update -y\n",
      "2021-09-02 00:10:40,100\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (sudo apt-get update -y)'\n",
      "Hit:2 http://security.ubuntu.com/ubuntu focal-security InRelease           \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease                     \n",
      "Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists... Done\n",
      "    (1/4) sudo apt-get install -y build-...\n",
      "2021-09-02 00:10:42,938\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (sudo apt-get install -y build-essential)'\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.8ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "    (2/4) pip install cvxpy\n",
      "2021-09-02 00:10:45,088\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (pip install cvxpy)'\n",
      "Requirement already satisfied: cvxpy in ./anaconda3/lib/python3.8/site-packages (1.1.15)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/lib/python3.8/site-packages (from cvxpy) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.15 in ./anaconda3/lib/python3.8/site-packages (from cvxpy) (1.19.5)\n",
      "Requirement already satisfied: ecos>=2 in ./anaconda3/lib/python3.8/site-packages (from cvxpy) (2.0.7.post1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in ./anaconda3/lib/python3.8/site-packages (from cvxpy) (0.6.2.post0)\n",
      "Requirement already satisfied: scs>=1.1.6 in ./anaconda3/lib/python3.8/site-packages (from cvxpy) (2.1.4)\n",
      "Requirement already satisfied: qdldl in ./anaconda3/lib/python3.8/site-packages (from osqp>=0.4.1->cvxpy) (0.1.5.post0)\n",
      "    (3/4) echo 'export PYTHONPATH=$HOME/...\n",
      "2021-09-02 00:10:47,109\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (echo '\"'\"'export PYTHONPATH=$HOME/dev_ws:$PYTHONPATH'\"'\"' >> ~/.bashrc)'\n",
      "  [7/7] Starting the Ray runtime\n",
      "2021-09-02 00:10:48,111\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (export RAY_OVERRIDE_RESOURCES='\"'\"'{\"CPU\":1,\"GPU\":0,\"memory\":7516192768}'\"'\"';ray stop)'\n",
      "\u001b[32mStopped all 15 Ray processes.\u001b[39m\n",
      "\u001b[0m2021-09-02 00:10:50,378\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (export RAY_OVERRIDE_RESOURCES='\"'\"'{\"CPU\":1,\"GPU\":0,\"memory\":7516192768}'\"'\"';ulimit -n 65536; ray start --head --autoscaling-config=~/ray_bootstrap_config.yaml --dashboard-host 0.0.0.0)'\n",
      "\u001b[37mLocal node IP\u001b[39m: \u001b[1m192.168.78.51\u001b[22m\n",
      "2021-09-01 17:10:53,819\tINFO services.py:1263 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://192.168.78.51:8265\u001b[39m\u001b[22m\n",
      "\n",
      "\u001b[32m--------------------\u001b[39m\n",
      "\u001b[32mRay runtime started.\u001b[39m\n",
      "\u001b[32m--------------------\u001b[39m\n",
      "\n",
      "\u001b[36mNext steps\u001b[39m\n",
      "  To connect to this Ray runtime from another node, run\n",
      "  \u001b[1m  ray start --address='192.168.78.51:6379' --redis-password='5241590000000000'\u001b[22m\n",
      "  \n",
      "  Alternatively, use the following Python code:\n",
      "    \u001b[31mimport\u001b[39m\u001b[26m ray\n",
      "    ray\u001b[31m.\u001b[39m\u001b[26minit(address\u001b[31m=\u001b[39m\u001b[26m\u001b[33m'auto'\u001b[39m\u001b[26m, _redis_password\u001b[31m=\u001b[39m\u001b[26m\u001b[33m'5241590000000000'\u001b[39m\u001b[26m)\n",
      "  \n",
      "  To connect to this Ray runtime from outside of the cluster, for example to\n",
      "  connect to a remote cluster from your laptop directly, use the following\n",
      "  Python code:\n",
      "    \u001b[31mimport\u001b[39m\u001b[26m ray\n",
      "    ray\u001b[31m.\u001b[39m\u001b[26minit(address\u001b[31m=\u001b[39m\u001b[26m\u001b[33m'ray://<head_node_ip_address>:10001'\u001b[39m\u001b[26m)\n",
      "  \n",
      "  \u001b[4mIf connection fails, check your firewall settings and network configuration.\u001b[24m\n",
      "  \n",
      "  To terminate the Ray runtime, run\n",
      "  \u001b[1m  ray stop\u001b[22m\n",
      "\u001b[0m  New status: up-to-date\n",
      "\n",
      "Useful commands\n",
      "  Monitor autoscaling with\n",
      "    ray exec /root/kubeflow_ws/ray_ws/toy_ws/config/cluster.yaml 'tail -n 100 -f /tmp/ray/session_latest/logs/monitor*'\n",
      "  Connect to a terminal on the cluster head:\n",
      "    ray attach /root/kubeflow_ws/ray_ws/toy_ws/config/cluster.yaml\n",
      "  Get a remote shell to the cluster manually:\n",
      "    kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KUBECONFIG\"] = \"./config/magics_cluster.yaml\" #kubernetes\n",
    "! ray up config/cluster.yaml -y # update ray cluster + service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346a3c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClientContext(dashboard_url='192.168.78.51:8265', python_version='3.8.5', ray_version='1.6.0', ray_commit='b2b2901dd3144bf6ee10b01912353dd826eaa510', protocol_version='2021-05-20', _num_clients=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address=\"ray://192.168.100.108:32703\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b96cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init a new Data Manager here\n",
      "\u001b[2m\u001b[36m(pid=4391)\u001b[0m 260\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +3m58s)\u001b[0m Tip: use `ray status` to view detailed autoscaling status. To disable autoscaler event messages, you can set AUTOSCALER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +3m58s)\u001b[0m Adding 2 nodes of type head_node.\n",
      "\u001b[2m\u001b[36m(pid=2132, ip=192.168.72.14)\u001b[0m 261\n",
      "\u001b[2m\u001b[36m(pid=2139, ip=192.168.72.13)\u001b[0m 262\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +4m4s)\u001b[0m Adding 2 nodes of type head_node.\n",
      "\u001b[2m\u001b[36m(pid=4391)\u001b[0m 263\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +4m10s)\u001b[0m Adding 1 nodes of type head_node.\n",
      "\u001b[2m\u001b[36m(pid=2139, ip=192.168.72.13)\u001b[0m 264\n",
      "Total time = 58.22618770599365\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def ray_bundles(idx):\n",
    "    bundle_list, Z_list = ray.get(ray_env).create_bundles(idx,idx+1)\n",
    "    return  bundle_list,Z_list\n",
    "t1 = time.time()\n",
    "env = bundle.Evaluator()\n",
    "ray_env = ray.put(env)\n",
    "return_refs = [ray_bundles.remote(idx) for idx in range(260, 265)]\n",
    "return_items = ray.get(return_refs)\n",
    "print(f\"Total time = {time.time() - t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_items = [return_items[i][0][0] for i in range(len(return_items))]\n",
    "Z_items = [return_items[i][1][0] for i in range(len(return_items))]\n",
    "import pickle\n",
    "B_file = \"./Data/B_list.pkl\"\n",
    "Z_file = \"./Data/Z_list.pkl\"\n",
    "with open(B_file, 'wb') as f:\n",
    "    pickle.dump(B_items, f)\n",
    "with open(Z_file, 'wb') as f:\n",
    "    pickle.dump(Z_items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c93f965",
   "metadata": {},
   "source": [
    "## submit job to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a92f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting `max_workers` for node type `head_node` to the global `max_workers` value of 4. To avoid spawning worker nodes of type `head_node`, explicitly set `max_workers: 0` for `head_node`.\n",
      "Note that `max_workers: 0` was the default value prior to Ray 1.3.0. Your current version is Ray 1.6.0.\n",
      "See the docs for more information:\n",
      "https://docs.ray.io/en/master/cluster/config.html#cluster-configuration-node-max-workers\n",
      "https://docs.ray.io/en/master/cluster/config.html#full-configuration\n",
      "Loaded cached provider configuration\n",
      "If you experience issues with the cloud provider, try re-running the command with --no-config-cache.\n",
      "\u001b[0mSetting `max_workers` for node type `head_node` to the global `max_workers` value of 4. To avoid spawning worker nodes of type `head_node`, explicitly set `max_workers: 0` for `head_node`.\n",
      "Note that `max_workers: 0` was the default value prior to Ray 1.3.0. Your current version is Ray 1.6.0.\n",
      "See the docs for more information:\n",
      "https://docs.ray.io/en/master/cluster/config.html#cluster-configuration-node-max-workers\n",
      "https://docs.ray.io/en/master/cluster/config.html#full-configuration\n",
      "Loaded cached provider configuration\n",
      "If you experience issues with the cloud provider, try re-running the command with --no-config-cache.\n",
      "Setting `max_workers` for node type `head_node` to the global `max_workers` value of 4. To avoid spawning worker nodes of type `head_node`, explicitly set `max_workers: 0` for `head_node`.\n",
      "Note that `max_workers: 0` was the default value prior to Ray 1.3.0. Your current version is Ray 1.6.0.\n",
      "See the docs for more information:\n",
      "https://docs.ray.io/en/master/cluster/config.html#cluster-configuration-node-max-workers\n",
      "https://docs.ray.io/en/master/cluster/config.html#full-configuration\n",
      "2021-09-02 03:02:59,181\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-p8247: Running kubectl -n roboweb exec -it toy-cluster-ray-head-p8247 -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (python ~/train.py)'\n",
      "2021-09-01 20:03:01,053\tINFO worker.py:825 -- Connecting to existing Ray cluster at address: 192.168.78.51:6379\n",
      "init a new Data Manager here\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KUBECONFIG\"] = \"./config/magics_cluster.yaml\"\n",
    "!ray rsync_up config/cluster.yaml \"./Data\" \"~/.\"\n",
    "!ray submit config/cluster.yaml train.py \n",
    "!ray rsync_down config/cluster.yaml '~/Data/Z_list.pkl' './Data/.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a68c11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting `max_workers` for node type `head_node` to the global `max_workers` value of 4. To avoid spawning worker nodes of type `head_node`, explicitly set `max_workers: 0` for `head_node`.\n",
      "Note that `max_workers: 0` was the default value prior to Ray 1.3.0. Your current version is Ray 1.6.0.\n",
      "See the docs for more information:\n",
      "https://docs.ray.io/en/master/cluster/config.html#cluster-configuration-node-max-workers\n",
      "https://docs.ray.io/en/master/cluster/config.html#full-configuration\n",
      "Loaded cached provider configuration\n",
      "If you experience issues with the cloud provider, try re-running the command with --no-config-cache.\n",
      "Destroying cluster. Confirm [y/N]: y [automatic, due to --yes]\n",
      "Setting `max_workers` for node type `head_node` to the global `max_workers` value of 4. To avoid spawning worker nodes of type `head_node`, explicitly set `max_workers: 0` for `head_node`.\n",
      "Note that `max_workers: 0` was the default value prior to Ray 1.3.0. Your current version is Ray 1.6.0.\n",
      "See the docs for more information:\n",
      "https://docs.ray.io/en/master/cluster/config.html#cluster-configuration-node-max-workers\n",
      "https://docs.ray.io/en/master/cluster/config.html#full-configuration\n",
      "2021-08-28 22:21:22,590\tINFO command_runner.py:172 -- NodeUpdater: toy-cluster-ray-head-tf6vg: Running kubectl -n roboweb exec -it toy-cluster-ray-head-tf6vg -- bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && (ray stop)'\n",
      "\u001b[32mStopped all 14 Ray processes.\u001b[39m\n",
      "\u001b[0m2021-08-28 22:21:27,153\tINFO node_provider.py:171 -- KubernetesNodeProvider: calling delete_namespaced_pod\n",
      "2021-08-28 22:21:27,217\tINFO node_provider.py:171 -- KubernetesNodeProvider: calling delete_namespaced_pod\n",
      "2021-08-28 22:21:27,282\tINFO node_provider.py:171 -- KubernetesNodeProvider: calling delete_namespaced_pod\n",
      "Requested 3 nodes to shut down. [interval=1s]\n",
      "0 nodes remaining after 5 second(s).\n",
      "No nodes remaining.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KUBECONFIG\"] = \"./config/magics_cluster.yaml\" #kubernetes\n",
    "! ray down config/cluster.yaml -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4a9db",
   "metadata": {},
   "source": [
    "## TIPS for control ray cluster\n",
    "sync files:   ray rsync_up cluster.yaml 'bundle.py' '/home/ray/dev_ws/bundle.py'\n",
    "\n",
    "update denpendency:  ray up cluster.yaml\n",
    "\n",
    "connect through ssh:  ray attach cluster.yaml\n",
    "\n",
    "execute command on head: ray exec cluster.yaml \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
